# PPO Configuration
env_name: "CartPole-v1"
algorithm: "ppo"
total_timesteps: 100000
eval_freq: 5000
save_freq: 10000

# PPO Hyperparameters
learning_rate: 0.0003
gamma: 0.99
gae_lambda: 0.95
clip_ratio: 0.2
value_loss_coef: 0.5
entropy_coef: 0.01
max_grad_norm: 0.5
buffer_size: 2048
batch_size: 64
n_epochs: 10

# Training Settings
device: "auto"  # auto, cpu, cuda, mps
seed: 42
num_eval_episodes: 10

# Logging
log_dir: "logs"
tensorboard_log: true
verbose: 1
